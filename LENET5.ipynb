{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LENET5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tA2OtyLTZNt",
        "colab_type": "code",
        "outputId": "aabb1f21-a38a-414d-9064-375ca0840214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "n_class = 10\n",
        "batch_size = 128\n",
        "n_epochs = 20\n",
        "lr = 1e-3\n",
        "\n",
        "print('Loading MNIST dataset')\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = np.expand_dims(X_train, -1)\n",
        "n_train = X_train.shape[0]\n",
        "X_test = np.expand_dims(X_test, -1)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, n_class)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, n_class)\n",
        "\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "print(\"X_train.shape =\", X_train.shape)\n",
        "print(\"y_train.shape =\", y_train.shape)\n",
        "print(\"X_test.shape =\", X_test.shape)\n",
        "print(\"y_test.shape =\", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading MNIST dataset\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "X_train.shape = (60000, 28, 28, 1)\n",
            "y_train.shape = (60000, 10)\n",
            "X_test.shape = (10000, 28, 28, 1)\n",
            "y_test.shape = (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwegLyc7TzkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model= keras.Sequential([\n",
        "                           layers.Conv2D(20, kernel_size=(5,5), strides=(1, 1),padding=\"same\", activation='relu', input_shape=(28, 28, 1)),\n",
        "                           layers.MaxPool2D( pool_size = (2, 2),strides =  (2, 2)),\n",
        "                           layers.Conv2D(50, kernel_size=(5,5),strides=(1, 1), padding=\"same\", activation='relu'),\n",
        "                           layers.MaxPool2D( pool_size = (2, 2),strides =  (2, 2)),\n",
        "                           layers.Flatten(),\n",
        "                           layers.Dense(500, activation='relu'),\n",
        "                           layers.Dense(10, activation='softmax')                     \n",
        "  ])\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQTfp_qBYHS5",
        "colab_type": "code",
        "outputId": "79351f79-1969-4198-ae8f-6b896fb8c79c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "model=build_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 50)        25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2450)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 500)               1225500   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 1,256,080\n",
            "Trainable params: 1,256,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4gX5jkSZRSD",
        "colab_type": "code",
        "outputId": "ef3b91c0-253b-411e-b6f0-29b0f9ed4bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print('The average loss for epoch {} is {:7.2f} '.format(epoch, logs['loss'] ))\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(\n",
        "  X_train, y_train,batch_size=64,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[LossAndErrorPrintingCallback()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average loss for epoch 0 is    0.02 \n",
            "The average loss for epoch 1 is    0.02 \n",
            "The average loss for epoch 2 is    0.01 \n",
            "The average loss for epoch 3 is    0.01 \n",
            "The average loss for epoch 4 is    0.01 \n",
            "The average loss for epoch 5 is    0.01 \n",
            "The average loss for epoch 6 is    0.01 \n",
            "The average loss for epoch 7 is    0.01 \n",
            "The average loss for epoch 8 is    0.00 \n",
            "The average loss for epoch 9 is    0.00 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWWjDV_TlkEF",
        "colab_type": "code",
        "outputId": "7b142be5-2833-4058-9b25-df6f3c8459d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(loss, accuracy) = model.evaluate(\n",
        "    X_test, \n",
        "    y_test,\n",
        "    batch_size = 64, \n",
        "    verbose = 1)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 5s 35ms/step - loss: 0.0443 - accuracy: 0.9907\n",
            "0.9907000064849854\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}